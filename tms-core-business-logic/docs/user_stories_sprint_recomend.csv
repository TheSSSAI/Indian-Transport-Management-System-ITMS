"sprint_number","story_ids","total_points","sprint_goal","dependencies_resolved","story_id","epic","title","user_role","description","business_value","priority","story_points","dependencies","acceptance_criteria","technical_tasks","definition_of_done"
"1","[""US-001"",""US-004"",""US-058"",""US-070"",""US-006"",""US-011"",""US-015"",""US-019"",""US-020""]","23","Establish foundational system: User roles, RBAC, core master data models (Customer, Driver, Vehicle, Route, Material), and user login.","true","","","","","","","","","","","",""
"2","[""US-002"",""US-003"",""US-007"",""US-008"",""US-012"",""US-014"",""US-018"",""US-026"",""US-071"",""US-072"",""US-073""]","21","Complete Master Data Management (Edit, Deactivate) and implement core Trip Creation workflow with all necessary validations.","true","","","","","","","","","","","",""
"3","[""US-027"",""US-028"",""US-074"",""US-075"",""US-076"",""US-009"",""US-013""]","20","Implement Trip Assignment workflow with all compliance validations, and add document management capabilities to vehicles.","true","","","","","","","","","","","",""
"4","[""US-046"",""US-047"",""US-049"",""US-052"",""US-050""]","20","Deliver Driver Portal MVP: Login, view assigned trips, start a trip, log events, and upload Proof of Delivery.","true","","","","","","","","","","","",""
"5","[""US-053"",""US-054"",""US-032"",""US-033"",""US-034"",""US-077"",""US-030"",""US-031""]","20","Implement the complete Expense Submission and Approval workflow, and add core Trip Exception Handling (On Hold, Resume, Cancel).","true","","","","","","","","","","","",""
"6","[""US-044"",""US-035"",""US-085"",""US-084"",""US-083"",""US-086"",""US-082""]","14","Solidify financial calculations by implementing trip profitability, adding robust expense validations, and creating the draft invoice workflow.","true","","","","","","","","","","","",""
"7","[""US-037"",""US-087"",""US-038"",""US-088""]","36","CRITICAL: Implement the end-to-end GST E-Invoicing integration, including the GSP client, workflow, and failure/intervention handling. (This may need to be split across two sprints).","","","","","","","","","","","","",""
"8","[""US-039"",""US-040"",""US-042"",""US-043"",""US-060""]","17","Complete the core financial loop with payment recording and customer ledgers. Establish the foundational notification system and card management.","true","","","","","","","","","","","",""
"","","","","","US-089","Project Management","Admin executes a one-time data migration from the legacy system","Admin","As an Admin, I want to execute a well-defined process with supporting scripts to migrate key master data and open financial transactions from our legacy system into the new TMS, so that the system is populated with accurate, essential business data at go-live, ensuring operational continuity and a seamless transition for all users.","Enables business continuity by populating the new TMS with critical operational data (customers, vehicles, drivers, open invoices) before go-live. This avoids catastrophic data loss and eliminates the need for manual re-entry, facilitating a seamless cutover to the new system.","Must Have","20","[""US-006"",""US-011"",""US-015"",""US-037""]","[{""scenario"":""Successful migration of active customer master data"",""given"":""A clean CSV file containing active customers from the legacy system, formatted according to the defined data mapping specification"",""when"":""The Admin executes the customer migration process"",""then"":""All customer records from the file are created in the Odoo 'res.partner' model, all fields (Name, Billing Address, GSTIN, Contact Person) are mapped correctly, and the post-migration validation report shows the number of imported records matches the source file.""},{""scenario"":""Migration process is idempotent and prevents duplicate records"",""given"":""The customer migration process has already been run once successfully"",""when"":""The Admin re-runs the exact same customer migration process with the same source file"",""then"":""No duplicate customer records are created in the system, and the migration log indicates that the records were skipped because they already exist.""}]","[""Develop Python scripts for data extraction, transformation, and loading (ETL)""]","[""All acceptance criteria validated and passing in the staging environment."",""Migration scripts and supporting documentation are code-reviewed, approved, and merged into the main branch."",""Unit tests for key data transformation logic are implemented and achieve required coverage."",""A full end-to-end migration dry-run has been successfully completed in the staging environment, as per REQ-TRN-002."",""A detailed runbook/documentation for executing the migration in production is created and peer-reviewed.""]"
"","","","","","US-090","Project Management","Admin validates migrated data in a staging environment","Admin","As an Admin responsible for the system's go-live, I want to execute a dry-run of the data migration in a staging environment and receive a comprehensive validation report, so that I can verify data integrity, identify and fix any issues before the production cutover, and ensure a smooth and successful transition to the new TMS.","Mitigates the significant business risk of data loss, corruption, or a failed go-live. Ensures business continuity by verifying that all critical operational and financial data is accurately transferred to the new system. Builds confidence among stakeholders for the production cutover.","Must Have","13","[""US-089"",""US-006"",""US-011"",""US-015"",""US-039""]","[{""scenario"":""Successful execution of migration and validation scripts"",""given"":""A clean staging TMS database is available, and a complete data dump from the legacy system has been provided"",""when"":""The Admin executes the documented command to run the data migration dry-run, followed by the command to run the validation process"",""then"":""The scripts complete without unhandled errors, and a structured validation report (e.g., CSV or text file) is generated in a predefined location.""},{""scenario"":""Validation report shows successful financial reconciliation"",""given"":""The migration and validation process has been successfully executed"",""when"":""The Admin reviews the generated validation report"",""then"":""The report must contain a 'Financial Reconciliation' section that shows the sum of all open (unpaid) invoice balances from the source data matches the sum of all outstanding balances in the staging TMS customer ledgers.""},{""scenario"":""Validation report identifies data transformation or mapping errors"",""given"":""A legacy data dump contains records that violate the new system's validation rules (e.g., an invalid GSTIN format)"",""when"":""The migration and validation process is executed"",""then"":""The validation report must list the specific records that failed to migrate or were migrated with data integrity issues, along with a reason for the failure (e.g., 'Invalid GSTIN format for Customer ID 123').""}]","[""Develop Python scripts for post-migration data validation""]","[""All acceptance criteria validated and passing"",""Migration validation scripts are written, code-reviewed, and merged into the main branch."",""A successful dry-run has been demonstrated to the project stakeholders using the full legacy dataset."",""The Admin user has formally signed off on the process and its results."",""The staging environment reset procedure is documented and has been successfully tested."",""Story deployed and verified in staging environment""]"