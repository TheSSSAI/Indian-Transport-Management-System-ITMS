"risk_id","risk_category","risk_description","probability","impact","risk_score","priority_level","affected_tasks","root_cause","mitigation_strategy","contingency_plan","monitoring_trigger","owner","due_date","status"
"RISK-001","External","High probability of downtime, breaking changes, or poor performance from the mandatory third-party GST Suvidha Provider (GSP) API, which would block the legally required e-invoicing process and halt the entire financial settlement workflow.","3","5","15","High","EPIC-004 Financial Management, WS-008 GST E-Invoicing Integration, WI-021, WI-022, US-037, US-038, US-087","Dependency on an external, government-mandated API with unknown reliability and support quality, creating a single point of failure for a critical business function.","Implement the resilient integration pattern (synchronous with asynchronous fallback queue) from day one. Develop a comprehensive mock GSP API server for the CI pipeline to test all known success, failure, and timeout scenarios independently of the live sandbox.","The planned manual intervention workflow (US-038) where a Finance Officer can manually enter a pre-generated IRN is the primary contingency. Ensure this workflow is robust and well-documented.","Prometheus alert fires when the GSP API error rate exceeds 5% over a 15-minute window or P95 latency exceeds 5 seconds.","Lead Backend Developer","2025-03-15","Not Started"
"RISK-002","Quality","Poor data quality from the legacy system (undocumented fields, inconsistent formats, missing records) causes the one-time data migration to fail or introduce corrupt data into the new TMS, compromising user trust and operational integrity from day one.","4","5","20","High","EPIC-008 Data Migration & Go-Live, WI-053, WI-054, WI-055, WI-056, US-089, US-090","Lack of visibility into the quality and structure of the legacy data, which is a common issue in migration projects.","Schedule a dedicated 'Data Profiling & Cleansing' task before ETL script development. Involve business SMEs to validate transformation rules. Make all ETL scripts idempotent to allow for safe re-runs. Perform at least two full dry-runs in the staging environment.","Prepare a detailed cutover runbook that includes a clear go/no-go decision point based on the validation report from the final dry-run. If critical discrepancies exist, the go-live must be postponed. Have a clear rollback plan to the legacy system if production migration fails.","The post-migration validation script (WI-055) reports a record count mismatch greater than 0% or a financial reconciliation difference greater than â‚¹0.01.","System Administrator","2025-04-30","Not Started"
"RISK-003","Resource","The development team may lack the specialized DevOps expertise required to correctly implement, secure, and operate the complex production stack (EKS, Terraform, Prometheus, PostGIS), leading to deployment delays, security vulnerabilities, and an inability to troubleshoot production issues effectively.","4","4","16","High","EPIC-007 Infrastructure, Deployment & Operations, WS-013, WS-014, WS-015","The project's technology stack is broad and requires a niche combination of skills (Odoo, FastAPI, and advanced AWS/Kubernetes SRE) that may not be present in the core team.","Conduct a formal skills gap analysis. Allocate budget for targeted training or for a short-term, expert DevOps consultant to lead the initial setup and provide knowledge transfer. Mandate peer reviews for all Infrastructure as Code (IaC) changes.","Establish a support contract with AWS or a certified third-party DevOps provider to be engaged if the team is unable to resolve critical infrastructure or deployment issues within a predefined timeframe.","CI/CD pipeline deployment success rate drops below 90% for a week. A production infrastructure issue remains unresolved for more than 4 hours.","Project Manager","2025-02-28","Not Started"
"RISK-004","Timeline","A delay in completing foundational infrastructure tasks (EPIC-007), such as provisioning the EKS cluster or setting up the CI/CD pipeline, will create a cascading delay across all development epics, significantly jeopardizing the project timeline.","4","4","16","High","All Epics (EPIC-001 through EPIC-006)","Underestimation of the complexity and time required for IaC and CI/CD setup, combined with its position on the critical path for all application development.","Prioritize the Infrastructure and Deployment epic (EPIC-007) in the very first sprints. Break down IaC setup into smaller deliverables (e.g., VPC, then RDS, then EKS). Use a 'walking skeleton' approach to get a minimal end-to-end deployment working early.","Develop a simplified 'Phase 0' deployment target (e.g., using Docker Compose on a single EC2 instance) for early-stage development and feature validation, to run in parallel with the production-grade EKS setup.","The EKS cluster is not provisioned and accessible by the end of the second sprint. A basic CI/CD pipeline is not functional by the end of the third sprint.","DevOps Lead","2025-03-20","Not Started"
"RISK-005","Technical","The high-volume GPS data ingestion pipeline (microservice, RabbitMQ, Odoo consumer) fails to meet performance or reliability targets under load, causing data loss, high latency in location updates, or performance degradation of the core Odoo application.","3","4","12","Medium","EPIC-005 GPS Tracking & Geofencing, WI-025, WI-026, WI-028, WI-029","The inherent complexity of a distributed, asynchronous system designed for high throughput, with multiple potential points of failure.","Implement comprehensive monitoring on the RabbitMQ queue depth and consumer lag. The Odoo consumer must process messages in batches and be idempotent. Conduct targeted load testing on the FastAPI microservice and the Odoo consumer job early in the development cycle.","If the Odoo consumer becomes a bottleneck, plan for a technical spike to replace it with a more scalable, independent Python consumer service that writes directly to the PostgreSQL database, bypassing the Odoo ORM for this specific high-volume task.","RabbitMQ 'q.tms.location_updates' queue depth consistently exceeds 10,000 messages. End-to-end GPS latency (from microservice receipt to DB write) exceeds the 10-second NFR.","Lead Backend Developer","2025-04-15","Not Started"
"RISK-006","Technical","Poorly optimized Odoo record rules (`ir.rule`) or complex computed fields cause severe database performance degradation as data volume grows, leading to slow load times for critical views like the trip list or dashboard and a poor user experience.","4","3","12","Medium","WI-005 Record Rules, WI-020 Profitability Calculation, EPIC-006 Reporting","Writing `ir.rule` domain filters and computed field logic that is efficient for small datasets but does not scale, often by triggering N+1 query problems.","Mandate code reviews for all `ir.rule` and computed field implementations by a senior Odoo developer. Use the `EXPLAIN ANALYZE` PostgreSQL command to inspect the query plans generated by Odoo for these rules on a staging database with a large, representative dataset.","If a rule is found to be unperformant, a fallback strategy is to replace it with a more targeted security group permission or rewrite the feature using a custom action and controller that can employ a more optimized, direct SQL query.","The P95 response time for the Trip list view API endpoint exceeds 500ms. The Dashboard load time (LCP) exceeds the 3-second NFR.","Odoo Development Lead","2025-03-31","Not Started"